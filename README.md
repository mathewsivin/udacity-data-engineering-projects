# udacity-data-engineering-projects
Contains the projects completed in the udacity data engineering program. In these projects, models were created for user activity data for a music streaming app call Sparkify. 
The database and ETL pipeline was designed to create tables, to understand what songs users are listening to. 


# Data Lake 
In this project, you’ll build an ETL pipeline for a data lake. The data
resides in S3, in a directory of JSON logs on user activity on the app,
as well as a directory with JSON metadata on the songs in the app.
You will load data from S3, process the data into analytics tables
using Spark, and load them back into S3. You’ll deploy this Spark
process on a cluster using AWS.

# Cloud Data Warehouse 
In this project, you are tasked with building an ELT pipeline that
extracts their data from S3, stages them in Redshift, and transforms
data into a set of dimensional tables for their analytics team to
continue finding insights in what songs their users are listening to.

# Data Lake with Postgres
In this project, you’ll model user activity data for a music streaming
app called Sparkify. You’ll create a relational database and ETL
pipeline designed to optimize queries for understanding what songs
users are listening to. In PostgreSQL you will also define Fact and
Dimension tables and insert data into your new tables.

# 
In this project, you’ll continue your work on the music streaming
company’s data infrastructure by creating and automating a set of
data pipelines. You’ll configure and schedule data pipelines with
Airflow and monitor and debug production pipelines.
